<!DOCTYPE html>
<html lang="en">
<head>
<meta http-equiv="Content-Type" content="text/html; charset=UTF-8">
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<title>Chapter 7 Fine-tune the SetFit model (Step 4) | Peaks and Pits Playbook üèî üï≥Ô∏èÔ∏è</title>
<meta name="author" content="Jamie Hudson">
<meta name="description" content="The SetFit documentation provides a really nice overview of what SetFit actually is behind the scenes (very DS heavy, so analysts do not worry about understanding all of this) why this approach is...">
<meta name="generator" content="bookdown 0.34 with bs4_book()">
<meta property="og:title" content="Chapter 7 Fine-tune the SetFit model (Step 4) | Peaks and Pits Playbook üèî üï≥Ô∏èÔ∏è">
<meta property="og:type" content="book">
<meta property="og:url" content="https://jamiehshare.github.io/peaks-pits-bookdown/index.html/step-four.html">
<meta property="og:description" content="The SetFit documentation provides a really nice overview of what SetFit actually is behind the scenes (very DS heavy, so analysts do not worry about understanding all of this) why this approach is...">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="Chapter 7 Fine-tune the SetFit model (Step 4) | Peaks and Pits Playbook üèî üï≥Ô∏èÔ∏è">
<meta name="twitter:description" content="The SetFit documentation provides a really nice overview of what SetFit actually is behind the scenes (very DS heavy, so analysts do not worry about understanding all of this) why this approach is...">
<!-- JS --><script src="https://cdnjs.cloudflare.com/ajax/libs/clipboard.js/2.0.6/clipboard.min.js" integrity="sha256-inc5kl9MA1hkeYUt+EC3BhlIgyp/2jDIyBLS6k3UxPI=" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/fuse.js/6.4.6/fuse.js" integrity="sha512-zv6Ywkjyktsohkbp9bb45V6tEMoWhzFzXis+LrMehmJZZSys19Yxf1dopHx7WzIKxr5tK2dVcYmaCk2uqdjF4A==" crossorigin="anonymous"></script><script src="https://kit.fontawesome.com/6ecbd6c532.js" crossorigin="anonymous"></script><script src="libs/jquery-3.6.0/jquery-3.6.0.min.js"></script><meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">
<link href="libs/bootstrap-4.6.0/bootstrap.min.css" rel="stylesheet">
<script src="libs/bootstrap-4.6.0/bootstrap.bundle.min.js"></script><link href="libs/Lato-0.4.7/font.css" rel="stylesheet">
<link href="https://fonts.googleapis.com/css2?family=DM%20Mono&amp;display=swap" rel="stylesheet">
<link href="libs/DM_Serif_Text-0.4.7/font.css" rel="stylesheet">
<script src="libs/bs3compat-0.5.1/transition.js"></script><script src="libs/bs3compat-0.5.1/tabs.js"></script><script src="libs/bs3compat-0.5.1/bs3compat.js"></script><link href="libs/bs4_book-1.0.0/bs4_book.css" rel="stylesheet">
<script src="libs/bs4_book-1.0.0/bs4_book.js"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/autocomplete.js/0.38.0/autocomplete.jquery.min.js" integrity="sha512-GU9ayf+66Xx2TmpxqJpliWbT5PiGYxpaG8rfnBEk1LL8l1KGkRShhngwdXK1UgqhAzWpZHSiYPc09/NwDQIGyg==" crossorigin="anonymous"></script><script src="https://cdnjs.cloudflare.com/ajax/libs/mark.js/8.11.1/mark.min.js" integrity="sha512-5CYOlHXGh6QpOFA/TeTylKLWfB3ftPsde7AnmhuitiTX4K5SqCLBeKro6sPS8ilsz1Q4NRx3v8Ko2IBiszzdww==" crossorigin="anonymous"></script><!-- CSS --><style type="text/css">
    
    div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  </style>
</head>
<body data-spy="scroll" data-target="#toc">

<div class="container-fluid">
<div class="row">
  <header class="col-sm-12 col-lg-3 sidebar sidebar-book"><a class="sr-only sr-only-focusable" href="#content">Skip to main content</a>

    <div class="d-flex align-items-start justify-content-between">
      <h1>
        <a href="index.html" title="">Peaks and Pits Playbook üèî üï≥Ô∏èÔ∏è</a>
      </h1>
      <button class="btn btn-outline-primary d-lg-none ml-2 mt-1" type="button" data-toggle="collapse" data-target="#main-nav" aria-expanded="true" aria-controls="main-nav"><i class="fas fa-bars"></i><span class="sr-only">Show table of contents</span></button>
    </div>

    <div id="main-nav" class="collapse-lg">
      <form role="search">
        <input id="search" class="form-control" type="search" placeholder="Search" aria-label="Search">
</form>

      <nav aria-label="Table of contents"><h2>Table of contents</h2>
        <ul class="book-toc list-unstyled">
<li><a class="" href="index.html"><span class="header-section-number">1</span> Background information</a></li>
<li><a class="" href="intro.html"><span class="header-section-number">2</span> Introduction to Peaks and Pits</a></li>
<li><a class="" href="high-level-overview.html"><span class="header-section-number">3</span> High-level overview</a></li>
<li><a class="" href="step-one.html"><span class="header-section-number">4</span> Obtain posts (Step 1)</a></li>
<li><a class="" href="step-two.html"><span class="header-section-number">5</span> Identify project-specific exemplar peaks and pits (Step 2)</a></li>
<li><a class="" href="step-three.html"><span class="header-section-number">6</span> The human touch- find the exemplars (Step 3)</a></li>
<li><a class="active" href="step-four.html"><span class="header-section-number">7</span> Fine-tune the SetFit model (Step 4)</a></li>
<li><a class="" href="step-five.html"><span class="header-section-number">8</span> Run inference over all project data (Step 5)</a></li>
<li><a class="" href="step-six.html"><span class="header-section-number">9</span> The metal detector, GPT-3.5 (Step 6)</a></li>
<li><a class="" href="step-seven.html"><span class="header-section-number">10</span> Downstream flourishes (Step 7)</a></li>
<li><a class="" href="resources.html"><span class="header-section-number">11</span> Resources</a></li>
</ul>

        <div class="book-extra">
          <p><a id="book-repo" href="https://github.com/rstudio/bookdown-demo">View book source <i class="fab fa-github"></i></a></p>
        </div>
      </nav>
</div>
  </header><main class="col-sm-12 col-md-9 col-lg-7" id="content"><div id="step-four" class="section level1" number="7">
<h1>
<span class="header-section-number">7</span> Fine-tune the SetFit model (Step 4)<a class="anchor" aria-label="anchor" href="#step-four"><i class="fas fa-link"></i></a>
</h1>
<p>The <a href="https://huggingface.co/docs/setfit/index">SetFit documentation</a> provides a really nice overview of what SetFit actually is behind the scenes (very DS heavy, so analysts do not worry about understanding all of this) why this approach is suitable, and how to implement it.</p>
<p>Before training the SetFit model on our data we need to do some cleaning/wrangling on our fine-tuning datasets. Namely, we need to mask mentions of brand/product entities to avoid introducing bias- for example if a particular brand is predominantly mentioned in peak contexts in the training data, the model might learn to associate peak moments with that brand rather than learning the peak-language expressed in the text.</p>
<p>To do this, we use the a model based on Facebook‚Äôs RoBERTa model, <code>xlm-roberta-large-finetuned-conll03-english</code>, to perform NER recognition, and then mask the ORG and MISC entities using a <code>rivendell</code> function <code>ner_brand_product()</code> in R.</p>
<pre><code>!pip install datasets
!pip install transformers
import pandas as pd
from transformers import pipeline
from datasets import Dataset

# Load in dataset
input_df = pd.read_csv("path/to/sample/data/filename.csv")

# NER pipeline initialization
ner = pipeline("ner", model="xlm-roberta-large-finetuned-conll03-english", device=0, aggregation_strategy="simple")

# Convert DataFrame to Dataset
dataset = Dataset.from_pandas(input_df)

# Run NER on the 'message_og' column
results = ner(dataset["message_og"])

# Convert results to DataFrame
results_df = pd.DataFrame(results)

# Append 'universal_message_id' column from input_df to results_df
results_df['universal_message_id'] = input_df['universal_message_id']

# Save the modified results_df to a CSV file
results_df.to_csv("ner_results.csv", index=False)</code></pre>
<p>We can then use an additional couple of <code>rivendell</code> functions (<code>pp_brands()</code> and <code>pp_products()</code>) to mask specific brands and products from previous projects, before doing some <em>very</em> high level data cleaning- namely removing hashtags, mentions, URLs and emojis. We don‚Äôt want to do too much data cleaning because SetFit is based on embeddings, so keeping stop words, punctuation etc is needed to maintain semantic meaning in each post.</p>
<pre><code>ner_clean &lt;- rivendell::ner_brand_product(ner_df = ner_results,
                                          input_df = input_df,
                                          text_var = text_var)

output_df &lt;- input_df %&gt;%
  mutate(setfit_text = message_og,
         setfit_text = ifelse(!is.na(ner_clean$replacement_text),
                              ner_clean$replacement_text, message_og)) %&gt;%
  rivendell::pp_brands(text_var = setfit_text) %&gt;%
  rivendell::pp_products(text_var = setfit_text) %&gt;%
  ParseR::clean_text(text_var = setfit_text,
                     hashtags = FALSE,
                     mentions = FALSE,
                     emojis = FALSE, 
                     punctuation = TRUE,
                     digits = TRUE,
                     in_parallel = TRUE)</code></pre>
<p>At this step, we can split out our data into training, testing, and validation datasets. A good rule of thumb is to split the data 70% to training data, 15% to testing data, and 15% to validation data. By default, <a href="https://huggingface.co/docs/setfit/v1.0.3/en/conceptual_guides/sampling_strategies">SetFit oversamples</a> the minimum class within the training data, so we shouldn‚Äôt have to worry about imbalanced datasets. Indeed, our (Jamie and Aoife) experimentation has shown that class imbalance doesn‚Äôt seem to have a significant effect to the training/output of the SetFit model for peaks and pits.</p>
<p>We are now at the stage where we can actually fine-tune the model. The key parameters that seem to make a difference to SetFit are:</p>
<ul>
<li>The specific sentence transformer (ST) model used</li>
<li>Number of epochs</li>
<li>Number of sequence-pair generation iterations</li>
</ul>
<p>so it is worthwhile fine-tuning a few models with different hyperparameter values for these such as:</p>
<ul>
<li>Trying <code>paraphrase-mpnet-base-v2</code> or <code>all-mpnet-vase-v2</code>
</li>
<li>Epochs (1 or 2)</li>
<li>Iterations (5, 10, 20, 30)</li>
</ul>
<p>But try not to get to get stuck in the weeds here!</p>
<blockquote>
<p><strong>The perfect is the enemy of the good</strong></p>
</blockquote>
<p>We can access model performance on the testing dataset by looking at accuracy, precision, recall, and F1 scores. For peaks and pits, the most important metric is actually <strong>recall</strong> because in <a href="#gpt35-inference">step 6</a> we reclassify posts using GPT, so we want to make sure we are able to provide <em>as many true peak/pit moments as possible</em> to this step, even if it means we also provide a few false positives.</p>
<pre><code># Load a SetFit model from Hub
model = SetFitModel.from_pretrained("sentence-transformers/paraphrase-mpnet-base-v2")

from sklearn.metrics import precision_recall_fscore_support, accuracy_score

def compute_metrics(pred, label):
    precision, recall, f1, _ = precision_recall_fscore_support(y_true = label, y_pred = pred, average=None)
    acc = accuracy_score(label, pred)
    return {
    'accuracy': acc,
    'f1': f1,
    'precision': precision,
    'recall': recall
    }
    
# Create trainer
trainer = SetFitTrainer(
    model=model,
    train_dataset=train_ds,
    eval_dataset=test_ds,
    loss_class=CosineSimilarityLoss,
    metric=compute_metrics,
    batch_size=4,
    num_iterations=20, # The number of text pairs to generate for contrastive learning
    num_epochs=1, # The number of epochs to use for constrastive learning
    column_mapping={"masked_context": "text", "label": "label"} # Map dataset columns to text/label expected by trainer
)

# Train and evaluate
trainer.train()

metrics = trainer.evaluate()
metrics</code></pre>
<p>A bonus that can be done to check how well our model is able to separate the different classes in embedding space, is to visualise the 2-D structure of the embeddings and see how they cluster:</p>
<pre><code>from sklearn.preprocessing import MinMaxScaler
from umap import UMAP
import pandas as pd
import plotly.express as px

def print_2d_embeddings_per_epoch(embeddings, labels, title="Embeddings representation in last epoch"):
  X_scaled = MinMaxScaler().fit_transform(embeddings)
  umap_2d_components = UMAP(n_components=2, metric="cosine").fit(X_scaled).embedding_

  result_2d = pd.DataFrame(umap_2d_components, columns=['x', 'y'])
  result_2d['labels'] = labels

  fig = px.scatter(
    result_2d, x='x', y='y', color=labels,
    size=[1]*len(embeddings), size_max=5, title=title

    )

  fig.update_traces(mode="markers", selector=dict(type='scatter2d'))
  fig.show()

print_2d_embeddings_per_epoch(embeddings1, train_ds["label_text"], "Embeddings representation of training data")</code></pre>
<div class="figure">
<span style="display:block;" id="fig:unnamed-chunk-1"></span>
<img src="img/embedding_trained.png" alt="Trained embedding model" width="100%"><p class="caption">
Figure 1.1: Trained embedding model
</p>
</div>
<p>For comparison, this is what it looks like on an untrained model:</p>
<pre><code>paraphrase_model = SetFitModel.from_pretrained("sentence-transformers/paraphrase-mpnet-base-v2")
embeddings2 = paraphrase_model.model_body.encode(trainlist)
print_2d_embeddings_per_epoch(embeddings2, train_ds["label_text"], "Embeddings representation of training data with untrained model")</code></pre>
<div class="figure">
<span style="display:block;" id="fig:unnamed-chunk-2"></span>
<img src="img/embedding_untrained.png" alt="Untrained embedding model" width="100%"><p class="caption">
Figure 7.1: Untrained embedding model
</p>
</div>
<p>We can save our models to the Huggingface Hub, making note of the performance metrics each one in a Google Sheet as well (the same one as before is a good place, to keep all project-specific related info together).</p>
<p>Finally, now we are happy with our model performance based on the training and validation datasets, we can evaluate the performance of this final model using our testing data. This is data that the model has never seen, and we are hoping that the accuracy and performance is similar to that of the validation data. This is Machine Learning 101 and if a refresher is needed for this there are plenty of resources online looking at the role of training, validation, and testing data.</p>

</div>
  <div class="chapter-nav">
<div class="prev"><a href="step-three.html"><span class="header-section-number">6</span> The human touch- find the exemplars (Step 3)</a></div>
<div class="next"><a href="step-five.html"><span class="header-section-number">8</span> Run inference over all project data (Step 5)</a></div>
</div></main><div class="col-md-3 col-lg-2 d-none d-md-block sidebar sidebar-chapter">
    <nav id="toc" data-toggle="toc" aria-label="On this page"><h2>On this page</h2>
      <ul class="nav navbar-nav"><li><a class="nav-link" href="#step-four"><span class="header-section-number">7</span> Fine-tune the SetFit model (Step 4)</a></li></ul>

      <div class="book-extra">
        <ul class="list-unstyled">
<li><a id="book-source" href="https://github.com/rstudio/bookdown-demo/blob/master/06-finetune-setfit.Rmd">View source <i class="fab fa-github"></i></a></li>
          <li><a id="book-edit" href="https://github.com/rstudio/bookdown-demo/edit/master/06-finetune-setfit.Rmd">Edit this page <i class="fab fa-github"></i></a></li>
        </ul>
</div>
    </nav>
</div>

</div>
</div> <!-- .container -->

<footer class="bg-primary text-light mt-5"><div class="container"><div class="row">

  <div class="col-12 col-md-6 mt-3">
    <p>"<strong>Peaks and Pits Playbook üèî üï≥Ô∏èÔ∏è</strong>" was written by Jamie Hudson. It was last built on 2024-03-08.</p>
  </div>

  <div class="col-12 col-md-6 mt-3">
    <p>This book was built by the <a class="text-light" href="https://bookdown.org">bookdown</a> R package.</p>
  </div>

</div></div>
</footer>
</body>
</html>
